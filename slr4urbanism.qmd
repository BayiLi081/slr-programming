---
title: "Systematic Literature Review for Urbanism"
author: "Bayi Li"
date: `r Sys.Date()`
output: html
---

## Setup

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(pdftools)
library(revtools)
```

## Extract data

<!-- Add text extraction script or reference to Python code -->

## Load data (already extracted from PDFs)


## 1. Mapping case study locations

Input: 
- manual
- extracting location from title
- extracting location from abstract
- if multiple locations are mentioned, multiple records are created

Output:
- interactive map with Leaflet
- tiled grid map with template available for QGIS as well



## 2. Keyword wordclouds

Input: keywords

Output: Word clouds - can be overall or per time period



## 3. Text mining

Input: Full text, machine readable (this requires text to be extracted from PDFs prior to analysis)

### 3.1 Word cooccureence

What questions co-occur with a specific word of interest, e.g., segregation?

- using the LDA model and top words
- using word embeddings

Output: A bar chart with top words related to the word of interest

### 3.2 Topic modeling

- using LDA to identify dominant topics in a corpus of papers

#### 3.2.1 Topics across the corpus

Output: Bar charts showing top words in each topic

#### 3.2.2 Evolution of topics

Output: A line chart showing the relative importance of topics for a given period.












```{r extracttxt}
files <- list.files(path = "data/collection/PDFs", pattern = "*.pdf", full.names = TRUE)

my_list_output <- list()

for (file in files){
  # Extract text from the PDF
  text <- pdftools::pdf_text(file)
  # Split each line of text for every new line
  lines <- strsplit(text, "\n")[[1]]
  # list to store each new line of information in a key value pair
  info_list <- lapply(strsplit(lines, ": "), function(x) setNames(x[1], x[2]))
  # take the output lines in a single column of a data frame
  df <- do.call(rbind, info_list)
  # remove rows with NA
  df_cleaned <- na.omit(df)
  # select 4th row to end of the data frame
  df_rows <- data.frame(df_cleaned[4:nrow(df_cleaned), ])
  # rename single column of the dataframe
  names(df_rows) = c("Values")
  # remove leading and trailing spaces
  df_rows$Values <- trimws(df_rows$Values)
  # remove leading and trailing spaces
  df_rows$Values <- str_replace_all(df_rows$Values, "\\s+", " ")
  
  # select each row which is currently a character string separated by spaces
  # split each character from the string and recombine them with "-" separator
  # in the process we need to unlist and list the observations of each row
  process_row <- function(row) {
    mylist = row["Values"]
    mylist1 = paste0(unlist(as.list(unlist(strsplit(mylist, '[[:space:]]')))), collapse = "-")
    return(mylist1)
  }
  
  # apply the above function for all rows in the data-frame
  df_rows$ConcatenatedValues <- apply(df_rows, 1, process_row)
  
  # take 1st row value of df_cleaned which looks like unique identifier of the file
  id_value = df_cleaned[[1]]
  
  # extract the metric enclosed within parenthesis ()
  # find position of the string )- after which the metric value is mentioned for each row
  # extract the string of metric value bounded by "-" before and after
  # replace "," with decimal dot for each metric value
  # convert character string to numeric
  # transpose the metric as key and corresponding values grouped by the id variable
  # remove the second column which looks to be NA
  df_transformed = df_rows %>%
    extract(ConcatenatedValues, into = c("Metric"), regex = "\\(([^)]+)\\)", remove = FALSE) %>%
    mutate(StringPosition = str_locate(ConcatenatedValues, "\\)-")) %>%
    mutate(len = nchar(ConcatenatedValues)) %>%
    mutate(string = str_sub(ConcatenatedValues, start=StringPosition[,"end"], end=len)) %>%
    extract(string, into = c("Metric_Value"), regex = "\\-([^)]+)\\-", remove = FALSE) %>%
    select(Values, Metric, Metric_Value) %>%
    mutate(Metric_Value = str_replace(Metric_Value, ",", ".")) %>%
    mutate(Metric_Value = as.numeric(Metric_Value)) %>%
    mutate(id = id_value) %>%
    select(id, Metric, Metric_Value) %>%
    pivot_wider(names_from = Metric, values_from = Metric_Value) %>%
    select(-2)
  
  # store the output of each file in an empty list which can be accessed based on index
  my_list_output[[file]] <- df_transformed
}

## Remove unwanted objects from environment
rm(file, files, id_value, lines, text)
rm(df_rows, df_cleaned, df, info_list, process_row)

my_list_output <- apply(my_list_output,2,as.character)

# save the list as txt
write.table(my_list_output, file = "data/collection/textdf.txt", sep = "\t", row.names = FALSE)
```

```{r extracttxt}
fs::dir_ls("data/collection/PDFs") %>% 
  as.character() %>% 
  as_tibble() %>% 
  mutate(text = map_chr(value, function(x){
    pdftools::pdf_text(x) %>% 
      paste0(collapse = "") %>% 
      str_remove_all("[\\s\\n\\t\\d[a-z].]")
  })) -> textdf

textdf %>% 
  write_csv("data/collection/textdf.csv")

textdf
```



